{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "https://github.com/gmadaan15/pgte_eye_gaze/blob/main/pgte_eye_gaze.ipynb",
      "authorship_tag": "ABX9TyOpgoNjWw8AQovLWdvDY1b6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gmadaan15/pgte_eye_gaze/blob/main/pgte_eye_gaze.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7zQFDMjaaIjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mj4WuyHzPlYk",
        "outputId": "385e2061-4e80-4a37-b09d-328a7f67f69a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pgte_eye_gaze'...\n",
            "remote: Enumerating objects: 67, done.\u001b[K\n",
            "remote: Counting objects: 100% (67/67), done.\u001b[K\n",
            "remote: Compressing objects: 100% (66/66), done.\u001b[K\n",
            "remote: Total 67 (delta 24), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (67/67), 133.36 KiB | 14.82 MiB/s, done.\n",
            "Resolving deltas: 100% (24/24), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/gmadaan15/pgte_eye_gaze.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python pgte_eye_gaze/train_eval.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0Fx82vIViW4",
        "outputId": "e044c304-d36c-4c7a-ba42-6133f7298a8f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "\n",
            "Processing /content/drive/MyDrive/outputs_pgte/MPIIGaze1.h5/p00\n",
            "FOLD 0\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=2011, out_features=2048, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=2048, out_features=3, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=1, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=6, bias=True)\n",
            "  0% 0/1 [00:00<?, ?it/s]Starting epoch 1\n",
            "training for epoch:1\n",
            "Epoch 1/2, Gaze Loss: 84.24711281061172\n",
            "evaluating for epoch: 1\n",
            "Epoch 1/2, Gaze Loss: 25.10840030759573\n",
            "100% 1/1 [00:32<00:00, 32.03s/it]\n",
            "  0% 0/1 [00:00<?, ?it/s]Starting epoch 2\n",
            "training for epoch:2\n",
            "Epoch 2/2, Gaze Loss: 0.0907652658089751, SubjectWise Loss:0.1819888879570479\n",
            "evaluating for epoch: 2\n",
            "Epoch 2/2, Gaze Loss: 0.07670843346767087, SubjectWise Loss:0.1535020398556209\n",
            "100% 1/1 [00:30<00:00, 30.28s/it]\n",
            "Training process has finished. Saving trained model.\n",
            "FOLD 1\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=2011, out_features=2048, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=2048, out_features=3, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=1, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=6, bias=True)\n",
            "  0% 0/1 [00:00<?, ?it/s]Starting epoch 1\n",
            "training for epoch:1\n",
            "Epoch 1/2, Gaze Loss: 81.0551556814462\n",
            "evaluating for epoch: 1\n",
            "Epoch 1/2, Gaze Loss: 8.828215761110187\n",
            "100% 1/1 [00:28<00:00, 28.77s/it]\n",
            "  0% 0/1 [00:00<?, ?it/s]Starting epoch 2\n",
            "training for epoch:2\n",
            "Epoch 2/2, Gaze Loss: 0.11130299146383837, SubjectWise Loss:0.22541284072594564\n",
            "evaluating for epoch: 2\n",
            "Epoch 2/2, Gaze Loss: 0.093687089455258, SubjectWise Loss:0.19008234778388602\n",
            "100% 1/1 [00:30<00:00, 30.31s/it]\n",
            "Training process has finished. Saving trained model.\n",
            "torch.Size([2925, 2008])\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "  0% 0/2 [00:00<?, ?it/s]training for epoch:1\n",
            "evaluating for epoch: 1\n",
            "Epoch: 2 | train_loss: 0.3829 | eval_loss: 0.1908 | \n",
            " 50% 1/2 [00:02<00:02,  2.95s/it]training for epoch:2\n",
            "evaluating for epoch: 2\n",
            "Epoch: 3 | train_loss: 0.1908 | eval_loss: 0.1908 | \n",
            "100% 2/2 [00:05<00:00,  2.73s/it]\n",
            "\n",
            "Processing /content/drive/MyDrive/outputs_pgte/MPIIGaze1.h5/p01\n",
            "FOLD 0\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=2011, out_features=2048, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=2048, out_features=3, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=1, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=6, bias=True)\n",
            "  0% 0/1 [00:00<?, ?it/s]Starting epoch 1\n",
            "training for epoch:1\n",
            "Epoch 1/2, Gaze Loss: 82.19054112117738\n",
            "evaluating for epoch: 1\n",
            "Epoch 1/2, Gaze Loss: 35.63774931430817\n",
            "100% 1/1 [00:40<00:00, 40.19s/it]\n",
            "  0% 0/1 [00:00<?, ?it/s]Starting epoch 2\n",
            "training for epoch:2\n",
            "Epoch 2/2, Gaze Loss: 0.10268620145763015, SubjectWise Loss:0.23638422209974175\n",
            "evaluating for epoch: 2\n",
            "Epoch 2/2, Gaze Loss: 0.06582623652622595, SubjectWise Loss:0.1372098565347247\n",
            "100% 1/1 [00:29<00:00, 29.14s/it]\n",
            "Training process has finished. Saving trained model.\n",
            "FOLD 1\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=2011, out_features=2048, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=2048, out_features=3, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=1, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=6, bias=True)\n",
            "  0% 0/1 [00:00<?, ?it/s]Starting epoch 1\n",
            "training for epoch:1\n",
            "Epoch 1/2, Gaze Loss: 73.31026996858418\n",
            "evaluating for epoch: 1\n",
            "Epoch 1/2, Gaze Loss: 12.220760328695178\n",
            "100% 1/1 [00:28<00:00, 28.29s/it]\n",
            "  0% 0/1 [00:00<?, ?it/s]Starting epoch 2\n",
            "training for epoch:2\n",
            "  0% 0/1 [00:08<?, ?it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/pgte_eye_gaze/train_eval.py\", line 423, in <module>\n",
            "    queries, pref_vecs = train_gaze_model(group, output_dir, intial_num_epochs=1, num_epochs_cosine=1,\n",
            "  File \"/content/pgte_eye_gaze/train_eval.py\", line 255, in train_gaze_model\n",
            "    train_epoch(gaze_model,\n",
            "  File \"/content/pgte_eye_gaze/train_eval.py\", line 76, in train_epoch\n",
            "    outputs = gaze_model(data, pref_vec, store_queries=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/pgte_eye_gaze/gaze_model.py\", line 67, in forward\n",
            "    self.queries = torch.cat((self.queries, query.detach().cpu()), axis=0)\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4EL4V9alVz3A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}