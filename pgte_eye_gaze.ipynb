{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "https://github.com/gmadaan15/pgte_eye_gaze/blob/main/pgte_eye_gaze.ipynb",
      "authorship_tag": "ABX9TyPKa23/J4aOpmWWA+TZOJIp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gmadaan15/pgte_eye_gaze/blob/main/pgte_eye_gaze.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7zQFDMjaaIjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mj4WuyHzPlYk",
        "outputId": "72bd7b61-dd50-465c-ad1c-9683bfb4451c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pgte_eye_gaze'...\n",
            "remote: Enumerating objects: 76, done.\u001b[K\n",
            "remote: Counting objects: 100% (76/76), done.\u001b[K\n",
            "remote: Compressing objects: 100% (75/75), done.\u001b[K\n",
            "remote: Total 76 (delta 30), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (76/76), 136.56 KiB | 1.90 MiB/s, done.\n",
            "Resolving deltas: 100% (30/30), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/gmadaan15/pgte_eye_gaze.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python pgte_eye_gaze/train_eval.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0Fx82vIViW4",
        "outputId": "33d36be9-c07f-4a90-e75b-fbf610114459"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100% 528M/528M [00:03<00:00, 166MB/s]\n",
            "\n",
            "Processing /content/drive/MyDrive/outputs_pgte/MPIIGaze1.h5/p00\n",
            "FOLD 0\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=2011, out_features=2048, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=2048, out_features=3, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=1, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=6, bias=True)\n",
            "  0% 0/1 [00:00<?, ?it/s]Starting epoch 1\n",
            "training for epoch:1\n",
            "Epoch 1/2, Gaze Loss: 77.67226799577475\n",
            "evaluating for epoch: 1\n",
            "Epoch 1/2, Gaze Loss: 14.428352154791355\n",
            "100% 1/1 [00:37<00:00, 37.84s/it]\n",
            "  0% 0/1 [00:00<?, ?it/s]Starting epoch 2\n",
            "training for epoch:2\n",
            "Epoch 2/2, Gaze Loss: 0.11780470399990108, SubjectWise Loss:0.23625860778523272\n",
            "evaluating for epoch: 2\n",
            "Epoch 2/2, Gaze Loss: 0.18188657921031526, SubjectWise Loss:0.3646722412337371\n",
            "100% 1/1 [00:29<00:00, 29.40s/it]\n",
            "Training process has finished. Saving trained model.\n",
            "FOLD 1\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=2011, out_features=2048, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=2048, out_features=3, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=1, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=6, bias=True)\n",
            "  0% 0/1 [00:00<?, ?it/s]Starting epoch 1\n",
            "training for epoch:1\n",
            "Epoch 1/2, Gaze Loss: 103.60058587417006\n",
            "evaluating for epoch: 1\n",
            "Epoch 1/2, Gaze Loss: 51.35966941714287\n",
            "100% 1/1 [00:28<00:00, 28.25s/it]\n",
            "  0% 0/1 [00:00<?, ?it/s]Starting epoch 2\n",
            "training for epoch:2\n",
            "Epoch 2/2, Gaze Loss: 0.09498867398647011, SubjectWise Loss:0.19159494922623607\n",
            "evaluating for epoch: 2\n",
            "Epoch 2/2, Gaze Loss: 0.09285118744347265, SubjectWise Loss:0.18584514600657376\n",
            "100% 1/1 [00:30<00:00, 30.42s/it]\n",
            "Training process has finished. Saving trained model.\n",
            "torch.Size([2925, 2008])\n",
            "\n",
            "Processing /content/drive/MyDrive/outputs_pgte/MPIIGaze1.h5/p01\n",
            "FOLD 0\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=2011, out_features=2048, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=2048, out_features=3, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=1, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=6, bias=True)\n",
            "  0% 0/1 [00:00<?, ?it/s]Starting epoch 1\n",
            "training for epoch:1\n",
            "  0% 0/1 [00:06<?, ?it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/pgte_eye_gaze/train_eval.py\", line 423, in <module>\n",
            "    queries, pref_vecs = train_gaze_model(group, output_dir, intial_num_epochs=1, num_epochs_cosine=1,\n",
            "  File \"/content/pgte_eye_gaze/train_eval.py\", line 224, in train_gaze_model\n",
            "    train_epoch(gaze_model,\n",
            "  File \"/content/pgte_eye_gaze/train_eval.py\", line 54, in train_epoch\n",
            "    for i, data in enumerate(trainloader, 0):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 631, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 675, in _next_data\n",
            "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/content/pgte_eye_gaze/data.py\", line 74, in __getitem__\n",
            "    \"side\" : self.sides[idx],\n",
            "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
            "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/h5py/_hl/dataset.py\", line 758, in __getitem__\n",
            "    return self._fast_reader.read(args)\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python pgte_eye_gaze/train_eval_calib.py"
      ],
      "metadata": {
        "id": "4EL4V9alVz3A",
        "outputId": "c45fcd5f-cac0-457e-e991-1320a84d0f56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "\n",
            "Processing /content/drive/MyDrive/outputs_pgte/MPIIGaze1.h5/p00\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "  0% 0/2 [00:00<?, ?it/s]training for epoch:1\n",
            "evaluating for epoch: 1\n",
            "Epoch: 2 | train_loss: 0.2223 | eval_loss: 0.1926 | \n",
            " 50% 1/2 [00:03<00:03,  3.92s/it]training for epoch:2\n",
            "evaluating for epoch: 2\n",
            "Epoch: 3 | train_loss: 0.1926 | eval_loss: 0.1926 | \n",
            "100% 2/2 [00:06<00:00,  3.22s/it]\n",
            "\n",
            "Processing /content/drive/MyDrive/outputs_pgte/MPIIGaze1.h5/p01\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/pgte_eye_gaze/train_eval_calib.py\", line 27, in <module>\n",
            "    queries = torch.load(\"{}/queries.pth\".format(output_dir))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 997, in load\n",
            "    with _open_file_like(f, 'rb') as opened_file:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 444, in _open_file_like\n",
            "    return _open_file(name_or_buffer, mode)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 425, in __init__\n",
            "    super().__init__(open(name, mode))\n",
            "FileNotFoundError: [Errno 2] No such file or directory: './checkpoints/p01/queries.pth'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LpgF7-m-CzHG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}