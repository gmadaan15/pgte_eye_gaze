{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1GLqB1fO805gTcFBet3H9k0uxj2jwvEfS",
      "authorship_tag": "ABX9TyORteichWW4YK8tLG/9UUhb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gmadaan15/pgte_eye_gaze/blob/main/pgte_eye_gaze.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7zQFDMjaaIjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mj4WuyHzPlYk",
        "outputId": "aa941c32-d880-41fd-e35c-0440381aa883"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pgte_eye_gaze'...\n",
            "remote: Enumerating objects: 49, done.\u001b[K\n",
            "remote: Counting objects: 100% (49/49), done.\u001b[K\n",
            "remote: Compressing objects: 100% (48/48), done.\u001b[K\n",
            "remote: Total 49 (delta 13), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (49/49), 124.48 KiB | 13.83 MiB/s, done.\n",
            "Resolving deltas: 100% (13/13), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/gmadaan15/pgte_eye_gaze.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python pgte_eye_gaze/train_eval.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0Fx82vIViW4",
        "outputId": "28ac4a8c-5a9f-43f6-d7ff-296e8031a478"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100% 528M/528M [00:05<00:00, 94.3MB/s]\n",
            "\n",
            "Processing /content/drive/MyDrive/outputs_pgte/MPIIGaze1.h5/p00\n",
            "FOLD 0\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=2011, out_features=2048, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=2048, out_features=3, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=1, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=6, bias=True)\n",
            "  0% 0/2 [00:00<?, ?it/s]Starting epoch 1\n",
            "training for epoch:1\n",
            "Epoch 1/4, Gaze Loss: 107.93879343941808\n",
            "evaluating for epoch: 1\n",
            "Epoch 1/4, Gaze Loss: 15.02769349515438\n",
            " 50% 1/2 [00:46<00:46, 46.47s/it]Starting epoch 2\n",
            "training for epoch:2\n",
            "Epoch 2/4, Gaze Loss: 25.100078143179417\n",
            "evaluating for epoch: 2\n",
            "Epoch 2/4, Gaze Loss: 8.025706171989441\n",
            "100% 2/2 [01:15<00:00, 38.00s/it]\n",
            "  0% 0/2 [00:00<?, ?it/s]Starting epoch 3\n",
            "training for epoch:3\n",
            "Epoch 3/4, Gaze Loss: 0.10149613140411548, SubjectWise Loss:0.20450391436040197\n",
            "evaluating for epoch: 3\n",
            "Epoch 3/4, Gaze Loss: 0.08787974498763278, SubjectWise Loss:0.17669647942120964\n",
            " 50% 1/2 [00:29<00:29, 29.31s/it]Starting epoch 4\n",
            "training for epoch:4\n",
            "Epoch 4/4, Gaze Loss: 0.03399129323152755, SubjectWise Loss:0.06800927919790199\n",
            "evaluating for epoch: 4\n",
            "Epoch 4/4, Gaze Loss: 0.08280344473550448, SubjectWise Loss:0.16563672018614975\n",
            "100% 2/2 [00:58<00:00, 29.23s/it]\n",
            "Training process has finished. Saving trained model.\n",
            "FOLD 1\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=2011, out_features=2048, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=2048, out_features=3, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=1, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=6, bias=True)\n",
            "  0% 0/2 [00:00<?, ?it/s]Starting epoch 1\n",
            "training for epoch:1\n",
            "Epoch 1/4, Gaze Loss: 96.2539786696434\n",
            "evaluating for epoch: 1\n",
            "Epoch 1/4, Gaze Loss: 18.13488009572029\n",
            " 50% 1/2 [00:28<00:28, 28.35s/it]Starting epoch 2\n",
            "training for epoch:2\n",
            "Epoch 2/4, Gaze Loss: 27.743620187044144\n",
            "evaluating for epoch: 2\n",
            "Epoch 2/4, Gaze Loss: 12.218672536313534\n",
            "100% 2/2 [00:56<00:00, 28.42s/it]\n",
            "  0% 0/2 [00:00<?, ?it/s]Starting epoch 3\n",
            "training for epoch:3\n",
            "Epoch 3/4, Gaze Loss: 0.07069442280704862, SubjectWise Loss:0.1421175237122046\n",
            "evaluating for epoch: 3\n",
            "Epoch 3/4, Gaze Loss: 0.03921691547273784, SubjectWise Loss:0.07849290841133208\n",
            " 50% 1/2 [00:29<00:29, 29.45s/it]Starting epoch 4\n",
            "training for epoch:4\n",
            "Epoch 4/4, Gaze Loss: 0.03411693746738975, SubjectWise Loss:0.06823945854736473\n",
            "evaluating for epoch: 4\n",
            "Epoch 4/4, Gaze Loss: 0.025886246783507837, SubjectWise Loss:0.05177249356701567\n",
            "100% 2/2 [00:58<00:00, 29.45s/it]\n",
            "Training process has finished. Saving trained model.\n",
            "FOLD 2\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=2011, out_features=2048, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=2048, out_features=3, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=1, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=6, bias=True)\n",
            "  0% 0/2 [00:00<?, ?it/s]Starting epoch 1\n",
            "training for epoch:1\n",
            "Epoch 1/4, Gaze Loss: 97.96370547264814\n",
            "evaluating for epoch: 1\n",
            "Epoch 1/4, Gaze Loss: 4.990959350019693\n",
            " 50% 1/2 [00:28<00:28, 28.41s/it]Starting epoch 2\n",
            "training for epoch:2\n",
            "Epoch 2/4, Gaze Loss: 28.834830839186907\n",
            "evaluating for epoch: 2\n",
            "Epoch 2/4, Gaze Loss: 5.221858028322458\n",
            "100% 2/2 [00:56<00:00, 28.42s/it]\n",
            "  0% 0/2 [00:00<?, ?it/s]Starting epoch 3\n",
            "training for epoch:3\n",
            "Epoch 3/4, Gaze Loss: 0.08747266416053316, SubjectWise Loss:0.1754945191100189\n",
            "evaluating for epoch: 3\n",
            "Epoch 3/4, Gaze Loss: 0.10775449177300608, SubjectWise Loss:0.21555999626178998\n",
            " 50% 1/2 [00:29<00:29, 29.26s/it]Starting epoch 4\n",
            "training for epoch:4\n",
            "Epoch 4/4, Gaze Loss: 0.03549256430360339, SubjectWise Loss:0.07100162658293703\n",
            "evaluating for epoch: 4\n",
            "Epoch 4/4, Gaze Loss: 0.06280674724965482, SubjectWise Loss:0.12563282976279389\n",
            "100% 2/2 [00:58<00:00, 29.29s/it]\n",
            "Training process has finished. Saving trained model.\n",
            "FOLD 3\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=2011, out_features=2048, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=2048, out_features=3, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=1, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=6, bias=True)\n",
            "  0% 0/2 [00:00<?, ?it/s]Starting epoch 1\n",
            "training for epoch:1\n",
            "Epoch 1/4, Gaze Loss: 92.47633434273303\n",
            "evaluating for epoch: 1\n",
            "Epoch 1/4, Gaze Loss: 8.910086007788777\n",
            " 50% 1/2 [00:28<00:28, 28.44s/it]Starting epoch 2\n",
            "training for epoch:2\n",
            "Epoch 2/4, Gaze Loss: 30.664654653519392\n",
            "evaluating for epoch: 2\n",
            "Epoch 2/4, Gaze Loss: 5.518857596442103\n",
            "100% 2/2 [00:56<00:00, 28.49s/it]\n",
            "  0% 0/2 [00:00<?, ?it/s]Starting epoch 3\n",
            "training for epoch:3\n",
            "Epoch 3/4, Gaze Loss: 0.08624877681504338, SubjectWise Loss:0.17327313170904998\n",
            "evaluating for epoch: 3\n",
            "Epoch 3/4, Gaze Loss: 0.11548820455130693, SubjectWise Loss:0.23311561396395838\n",
            " 50% 1/2 [00:29<00:29, 29.26s/it]Starting epoch 4\n",
            "training for epoch:4\n",
            "Epoch 4/4, Gaze Loss: 0.031558822748273506, SubjectWise Loss:0.06312278782116065\n",
            "evaluating for epoch: 4\n",
            "Epoch 4/4, Gaze Loss: 0.03667952067445259, SubjectWise Loss:0.07335904134890518\n",
            "100% 2/2 [00:58<00:00, 29.42s/it]\n",
            "Training process has finished. Saving trained model.\n",
            "FOLD 4\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=2011, out_features=2048, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=2048, out_features=3, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=1, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=6, bias=True)\n",
            "  0% 0/2 [00:00<?, ?it/s]Starting epoch 1\n",
            "training for epoch:1\n",
            "Epoch 1/4, Gaze Loss: 77.643619004637\n",
            "evaluating for epoch: 1\n",
            "Epoch 1/4, Gaze Loss: 4.016793008893728\n",
            " 50% 1/2 [00:28<00:28, 28.54s/it]Starting epoch 2\n",
            "training for epoch:2\n",
            "Epoch 2/4, Gaze Loss: 27.070552237331867\n",
            "evaluating for epoch: 2\n",
            "Epoch 2/4, Gaze Loss: 7.487207189202309\n",
            "100% 2/2 [00:56<00:00, 28.48s/it]\n",
            "  0% 0/2 [00:00<?, ?it/s]Starting epoch 3\n",
            "training for epoch:3\n",
            "Epoch 3/4, Gaze Loss: 0.07700794670768972, SubjectWise Loss:0.1544514167736008\n",
            "evaluating for epoch: 3\n",
            "Epoch 3/4, Gaze Loss: 0.03699531081459812, SubjectWise Loss:0.07401469828107872\n",
            " 50% 1/2 [00:29<00:29, 29.27s/it]Starting epoch 4\n",
            "training for epoch:4\n",
            "Epoch 4/4, Gaze Loss: 0.030352686477805976, SubjectWise Loss:0.06072421771165861\n",
            "evaluating for epoch: 4\n",
            "Epoch 4/4, Gaze Loss: 0.027104595348843047, SubjectWise Loss:0.054209190697686094\n",
            "100% 2/2 [01:02<00:00, 31.25s/it]\n",
            "Training process has finished. Saving trained model.\n",
            "torch.Size([4680, 2008])\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "  0% 0/2 [00:00<?, ?it/s]training for epoch:1\n",
            "evaluating for epoch: 1\n",
            "Epoch: 2 | train_loss: nan | eval_loss: nan | \n",
            " 50% 1/2 [00:16<00:16, 16.47s/it]training for epoch:2\n",
            "evaluating for epoch: 2\n",
            "Epoch: 3 | train_loss: nan | eval_loss: nan | \n",
            "100% 2/2 [00:32<00:00, 16.20s/it]\n",
            "\n",
            "Processing /content/drive/MyDrive/outputs_pgte/MPIIGaze1.h5/p01\n",
            "FOLD 0\n",
            "--------------------------------\n",
            "Reset trainable parameters of layer = Linear(in_features=2011, out_features=2048, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=2048, out_features=3, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=1, out_features=32, bias=True)\n",
            "Reset trainable parameters of layer = Linear(in_features=32, out_features=6, bias=True)\n",
            "  0% 0/2 [00:00<?, ?it/s]Starting epoch 1\n",
            "training for epoch:1\n",
            "  0% 0/2 [00:07<?, ?it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/pgte_eye_gaze/train_eval.py\", line 417, in <module>\n",
            "    queries, pref_vecs = train_gaze_model(group, output_dir, intial_num_epochs = 2, num_epochs_cosine = 2, person_id=person_id, k_folds=k_folds)\n",
            "  File \"/content/pgte_eye_gaze/train_eval.py\", line 224, in train_gaze_model\n",
            "    train_epoch(gaze_model,\n",
            "  File \"/content/pgte_eye_gaze/train_eval.py\", line 51, in train_epoch\n",
            "    for i, data in enumerate(trainloader, 0):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 631, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 675, in _next_data\n",
            "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/content/pgte_eye_gaze/data.py\", line 71, in __getitem__\n",
            "    \"face\" : self.preprocess_image(np.array(self.faces[idx])),\n",
            "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
            "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/h5py/_hl/dataset.py\", line 758, in __getitem__\n",
            "    return self._fast_reader.read(args)\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4EL4V9alVz3A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}